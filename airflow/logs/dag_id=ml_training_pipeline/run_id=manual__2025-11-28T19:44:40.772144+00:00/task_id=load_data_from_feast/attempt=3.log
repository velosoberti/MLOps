[2025-11-28T20:01:14.192+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-11-28T20:01:14.233+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ml_training_pipeline.load_data_from_feast manual__2025-11-28T19:44:40.772144+00:00 [queued]>
[2025-11-28T20:01:14.245+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ml_training_pipeline.load_data_from_feast manual__2025-11-28T19:44:40.772144+00:00 [queued]>
[2025-11-28T20:01:14.245+0000] {taskinstance.py:2306} INFO - Starting attempt 3 of 3
[2025-11-28T20:01:14.264+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): load_data_from_feast> on 2025-11-28 19:44:40.772144+00:00
[2025-11-28T20:01:14.278+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=526) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-11-28T20:01:14.279+0000] {standard_task_runner.py:63} INFO - Started process 560 to run task
[2025-11-28T20:01:14.280+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'ml_training_pipeline', 'load_data_from_feast', 'manual__2025-11-28T19:44:40.772144+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/train.py', '--cfg-path', '/tmp/tmpj8t9ofpg']
[2025-11-28T20:01:14.285+0000] {standard_task_runner.py:91} INFO - Job 34: Subtask load_data_from_feast
[2025-11-28T20:01:14.349+0000] {task_command.py:426} INFO - Running <TaskInstance: ml_training_pipeline.load_data_from_feast manual__2025-11-28T19:44:40.772144+00:00 [running]> on host 33d3f194c23b
[2025-11-28T20:01:14.469+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='data-team@example.com' AIRFLOW_CTX_DAG_OWNER='data_science_team' AIRFLOW_CTX_DAG_ID='ml_training_pipeline' AIRFLOW_CTX_TASK_ID='load_data_from_feast' AIRFLOW_CTX_EXECUTION_DATE='2025-11-28T19:44:40.772144+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-11-28T19:44:40.772144+00:00'
[2025-11-28T20:01:14.471+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-11-28T20:01:14.487+0000] {logging_mixin.py:188} INFO - Carregando dados do Feast...
[2025-11-28T20:01:14.962+0000] {registry.py:872} INFO - Registry cache expired, so refreshing
[2025-11-28T20:01:14.965+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/feast/feature_store.py:1207 RuntimeWarning: Retrieving datasets is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.
[2025-11-28T20:01:14.966+0000] {registry.py:872} INFO - Registry cache expired, so refreshing
[2025-11-28T20:01:15.029+0000] {logging_mixin.py:188} INFO - Dados carregados: (768, 7)
[2025-11-28T20:01:15.029+0000] {logging_mixin.py:188} INFO -    Colunas: ['SkinThickness', 'Outcome', 'event_timestamp', 'patient_id', 'Insulin', 'DiabetesPedigreeFunction', 'BMI']
[2025-11-28T20:01:15.062+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-11-28T20:01:15.063+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-11-28T20:01:15.070+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ml_training_pipeline, task_id=load_data_from_feast, run_id=manual__2025-11-28T19:44:40.772144+00:00, execution_date=20251128T194440, start_date=20251128T200114, end_date=20251128T200115
[2025-11-28T20:01:15.096+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-11-28T20:01:15.118+0000] {taskinstance.py:3498} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-11-28T20:01:15.122+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
