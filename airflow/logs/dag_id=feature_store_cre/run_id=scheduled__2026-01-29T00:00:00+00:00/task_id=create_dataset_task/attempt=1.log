[2026-01-30T14:47:19.015+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2026-01-30T14:47:19.084+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: feature_store_cre.create_dataset_task scheduled__2026-01-29T00:00:00+00:00 [queued]>
[2026-01-30T14:47:19.103+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: feature_store_cre.create_dataset_task scheduled__2026-01-29T00:00:00+00:00 [queued]>
[2026-01-30T14:47:19.104+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2026-01-30T14:47:19.126+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): create_dataset_task> on 2026-01-29 00:00:00+00:00
[2026-01-30T14:47:19.146+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=234) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2026-01-30T14:47:19.148+0000] {standard_task_runner.py:63} INFO - Started process 241 to run task
[2026-01-30T14:47:19.154+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'feature_store_cre', 'create_dataset_task', 'scheduled__2026-01-29T00:00:00+00:00', '--job-id', '98', '--raw', '--subdir', 'DAGS_FOLDER/feature_store.py', '--cfg-path', '/tmp/tmp3a6h531o']
[2026-01-30T14:47:19.157+0000] {standard_task_runner.py:91} INFO - Job 98: Subtask create_dataset_task
[2026-01-30T14:47:19.223+0000] {task_command.py:426} INFO - Running <TaskInstance: feature_store_cre.create_dataset_task scheduled__2026-01-29T00:00:00+00:00 [running]> on host 0849d884f7fa
[2026-01-30T14:47:19.330+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='feature_store_cre' AIRFLOW_CTX_TASK_ID='create_dataset_task' AIRFLOW_CTX_EXECUTION_DATE='2026-01-29T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2026-01-29T00:00:00+00:00'
[2026-01-30T14:47:19.332+0000] {taskinstance.py:430} INFO - ::endgroup::
[2026-01-30T14:47:20.147+0000] {registry.py:872} INFO - Registry cache expired, so refreshing
[2026-01-30T14:47:20.153+0000] {logging_mixin.py:188} INFO - Lendo entidades de: /home/luisveloso/MLOps_projects/data/artifacts/target.parquet
[2026-01-30T14:47:20.200+0000] {logging_mixin.py:188} INFO - Recuperando features hist√≥ricas...
[2026-01-30T14:47:20.200+0000] {utils.py:750} WARNING - _list_feature_views will make breaking changes. Please use _list_batch_feature_views instead. _list_feature_views will behave like _list_all_feature_views in the future.
[2026-01-30T14:47:20.201+0000] {registry.py:872} INFO - Registry cache expired, so refreshing
[2026-01-30T14:47:20.203+0000] {registry.py:872} INFO - Registry cache expired, so refreshing
[2026-01-30T14:47:20.203+0000] {registry.py:872} INFO - Registry cache expired, so refreshing
[2026-01-30T14:47:20.209+0000] {registry.py:872} INFO - Registry cache expired, so refreshing
[2026-01-30T14:47:20.213+0000] {logging_mixin.py:188} INFO - Persistindo Dataset via Feast...
[2026-01-30T14:47:20.214+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/feast/feature_store.py:1155 RuntimeWarning: Saving dataset is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.
[2026-01-30T14:47:20.214+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2026-01-30T14:47:20.215+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/feature_store.py", line 50, in create_dataset_task
    store.create_saved_dataset(
  File "/home/airflow/.local/lib/python3.12/site-packages/feast/feature_store.py", line 1180, in create_saved_dataset
    from_.persist(storage=storage, allow_overwrite=allow_overwrite)
  File "/home/airflow/.local/lib/python3.12/site-packages/feast/infra/offline_stores/dask.py", line 100, in persist
    raise SavedDatasetLocationAlreadyExists(location=storage.file_options.uri)
feast.errors.SavedDatasetLocationAlreadyExists: Saved dataset location /home/luisveloso/MLOps_projects/feature_store/data/my_training_dataset2.parquet already exists.
[2026-01-30T14:47:20.229+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=feature_store_cre, task_id=create_dataset_task, run_id=scheduled__2026-01-29T00:00:00+00:00, execution_date=20260129T000000, start_date=20260130T144719, end_date=20260130T144720
[2026-01-30T14:47:20.246+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 98 for task create_dataset_task (Saved dataset location /home/luisveloso/MLOps_projects/feature_store/data/my_training_dataset2.parquet already exists.; 241)
[2026-01-30T14:47:20.295+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2026-01-30T14:47:20.309+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2026-01-30T14:47:20.311+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
